import argparse
import os
import re

import pandas as pd
from pandarallel import pandarallel
from dotenv import load_dotenv
from tqdm.auto import tqdm
from tenacity import (
    retry,
    stop_after_attempt,
    wait_random_exponential
)
import openai

from create_fragment import PROMPT_TEMPLATES

load_dotenv()


def _prepare():
    tqdm.pandas()
    pandarallel.initialize(progress_bar=True, nb_workers=4)


def prepare_for_local_api():
    _prepare()
    openai.api_key = 'anything'
    openai.api_base = os.getenv('LOCAL_API_URL')


def prepare_for_official_openai_api():
    _prepare()
    openai.api_key = os.getenv('OPENAI_API_KEY')


@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))
def openai_chat_complete(prompt, model):
    response = openai.ChatCompletion.create(
        model=model,
        messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ],
        temperature=0.7,
        max_tokens=256,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        headers={'ngrok-skip-browser-warning': ''}
    )
    return response


def process_completion(row):
    completion = row['completion']
    completion_tokens = completion.usage.completion_tokens
    prompt_tokens = completion.usage.prompt_tokens
    finish_reason = completion.choices[0].finish_reason
    message = completion.choices[0].message.content
    regex = PROMPT_TEMPLATES[row['prompt_style']][1]
    result = re.search(regex, message)
    if not result:
        return None, None, message, completion_tokens, prompt_tokens, finish_reason, False
    else:
        choice = result.group('choice')
        explanation = result.group('explanation')
        return choice, explanation, message, completion_tokens, prompt_tokens, finish_reason, True


def query(prompts_df, model):
    prompts_df['completion'] = prompts_df['prompt'].parallel_apply(
        lambda prompt: openai_chat_complete(prompt, model)
    )

    # process completions
    new_columns = ['choice', 'explanation', 'full_completion', 'nr_tokens_compl', 'nr_tokens_prompt', 'finish_reason', 'success']
    prompts_df[new_columns] = prompts_df.apply(process_completion, result_type='expand', axis=1)

    return prompts_df


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='')

    parser.add_argument('--fragment_file', type=str)
    parser.add_argument('--model', type=str)
    parser.add_argument('--api', type=str, choices=['openai_official', 'local'], default='local')
    parser.add_argument('--output_dir', type=str, default='outputs/')
    parser.add_argument('--sample_n', type=int, default=100)
    parser.add_argument('--sample_seed', type=int, default=0)

    _args = parser.parse_args()
    _name = os.path.basename(_args.fragment_file).replace('prompts', 'results')

    if _args.api == 'openai_official':
        prepare_for_official_openai_api()
    elif _args.api == 'local':
        prepare_for_local_api()
    else:
        raise ValueError('unsupported api')

    _df = pd.read_json(_args.fragment_file, lines=True)

    _df = _df.sample(n=_args.sample_n, random_state=_args.sample_seed)

    _df = query(_df, _args.model)
    _df.to_json(
        os.path.join(_args.output_dir, _name),
        orient='records', lines=True
    )
