import random
import os
import argparse
import logging
import time

import duckdb
import pandas as pd
import requests
import yaml

LOGLEVEL = os.environ.get('LOGLEVEL', 'INFO').upper()
logging.basicConfig(level=LOGLEVEL)
logger = logging.getLogger('radd/create_fragment.py')


FRAGMENTS_DIR = 'fragments'
QUERY_RESULTS_DIR = 'query_results'

WD_SPARQL_ENDPOINT = 'https://query.wikidata.org/bigdata/namespace/wdq/sparql'

PROMPT_TEMPLATES = {
    'direct': (
        'Answer only with "Option 1" or "Option 2", explain your decision after.',
        r'Option (?P<choice>\d).?\s*(?P<explanation>.*)'
    ),
    'step_by_step1': (
        'First, consider both options briefly, thinking step by step.\n'
        'Finally, give your final answer simply as:\n'
        '"FINAL ANSWER: Option 1." or "FINAL ANSWER: Option 2.".',
        r'(?i)(?P<explanation>[\s\S]*)final answer: option (?P<choice>\d).*'
    ),
    'step_by_step4': (
        'When answering, please consider both options, and think step by step.\n'
        'As the final sentence include "FINAL ANSWER: x." where x is 1 or 2 and nothing else.\n'
        'DO NOT repeat the premises, only refer to their number.',
        r'(?i)(?P<explanation>[\s\S]*)final answer:(?: option)? (?P<choice>\d)'
    )
}


def load_fragment_definition(fragment_def_path):
    with open(fragment_def_path, 'r') as f:
        fragment_def = yaml.safe_load(f)
    return fragment_def


def query_wikidata(fragment_def, output_path):
    logger.info('Querying WikiData...')
    data = requests.get(WD_SPARQL_ENDPOINT, params={'query': fragment_def['query']}, headers={'Accept': 'text/csv'})
    with open(output_path, 'w') as query_file:
        query_file.write(data.text)
    logger.info(f'Result written to {output_path}.')
    return data


def create_fragment(fragment_def, csv_path, output_dir, prompt_style='direct'):
    ddb = duckdb.connect()

    # Load SPARQL query results into DuckDB.
    # Making sure that startTime and endTime are not NULL and that endTime > startTime.
    # Interpreting the timestamps properly.
    ddb.sql(f""" 
    CREATE OR REPLACE TABLE query_results AS 
    SELECT entity, entityLabel, relation, relationLabel, property, propertyLabel, 
        CAST(startTime AS DATE) AS startTime, CAST(endTime AS DATE) AS endTime
    FROM read_csv(
        '{csv_path}', 
        header=True, 
        timestampformat='%Y-%m-%dT%H:%M:%SZ',
        ignore_errors=True,
        columns={{
            'entity': 'VARCHAR',
            'entityLabel': 'VARCHAR',
            'relation': 'VARCHAR',
            'relationLabel': 'VARCHAR',
            'property': 'VARCHAR',
            'propertyLabel': 'VARCHAR',
            'startTime': 'TIMESTAMP',
            'endTime': 'TIMESTAMP'
        }}
    )
    WHERE startTime IS NOT NULL
    AND endTime IS NOT NULL
    AND endTime > startTime
    AND startTime > '1675-01-01'::DATE    -- Workaround for bug in DuckDB https://github.com/duckdb/duckdb/issues/6298
    """)

    # Create parts of prompts that are not dependent on the relation or property.
    query_results_df = ddb.query("SELECT * FROM query_results").df()
    grouped = query_results_df.groupby(by='entityLabel')

    entity_relation_strings = {
        entity_label: "\n".join([
            fragment_def['entity_relation_string'].format(
                entity=entity_label, relation=row[0],
                start_time=row[1].strftime(fragment_def['datetime_strf']),
                end_time=row[2].strftime(fragment_def['datetime_strf'])
            )
            for row in zip(relation_df['relationLabel'], relation_df['startTime'], relation_df['endTime'])
        ])
        for entity_label, relation_df in grouped
    }

    relation_property_strings = {
        entity_label: "\n".join({
            fragment_def['relation_property_string'].format(relation=row[0], property=row[1])
            for row in zip(relation_df['relationLabel'], relation_df['propertyLabel'])
        })
        for entity_label, relation_df in grouped
    }

    # Create the rest of the prompts.

    # Join table with itself on entityLabel to get pairs of relations for each entity.
    # Filter out pairs where the relations are the same, and pairs where the time spans overlap.
    property_pairs_df = ddb.query(f"""
    SELECT q1.entityLabel AS entityLabel, 
        q1.startTime AS startTime1,
        q1.endTime AS endTime1,
        q1.relationLabel AS relationLabel1, 
        q1.propertyLabel AS propertyLabel1,
        q2.startTime AS startTime2,
        q2.endTime AS endTime2,
        q2.relationLabel AS relationLabel2, 
        q2.propertyLabel AS propertyLabel2,
    FROM query_results as q1 INNER JOIN query_results as q2
    ON q1.entityLabel = q2.entityLabel AND q1.property != q2.property
    WHERE least(q1.endTime, q2.endTime) < greatest(q1.startTime, q2.startTime)
    AND q1.startTime < q2.startTime
    """).df()

    INTERPRETATION_INDEX = {
        1: 'de_dicto',      # we selected pairs where q1.startTime < q2.startTime
        2: 'de_re'
    }

    property_pairs_df.to_csv(
        os.path.join(output_dir, f"{fragment_def['key']}_pairs.csv")
    )

    def sample_date(start_date, end_date):
        """ Samples a date uniformly from the given date interval. """
        assert end_date > start_date
        i = random.randint(0, (end_date - start_date).days)
        date = start_date + pd.Timedelta(i, unit='days')
        return date

    def create_prompt(entity, property, start1, end1, relation1, start2, end2, relation2,
                      lbl_i, explicit_regularity=True, numbered_premises=True):
        question_date = sample_date(start1, end1).strftime('%B %Y')
        current_date = sample_date(start2, end2).strftime('%B %Y')

        lbl_str = INTERPRETATION_INDEX[lbl_i]
        relations = [(1, relation1), (2, relation2)]
        random.shuffle(relations)

        premise_strings = entity_relation_strings[entity] + '\n\n' + relation_property_strings[entity] + '\n\n'
        if explicit_regularity:
            premise_strings += fragment_def['explicit_regularity'] + '\n\n'

        premise_index = 1

        def number_premises(text):
            nonlocal premise_index
            result = ""
            for line in text.splitlines(True):
                if len(line) > 1:
                    result += f'(P{premise_index}) '
                    premise_index += 1
                result += line
            return result

        if numbered_premises:
            premise_strings = number_premises(premise_strings)

        prompt = 'Premises: \n'
        prompt += premise_strings
        prompt += 'Question: \n'
        prompt += f'If it is currently {current_date}, what is the most likely interpretation of the following sentence'
        prompt += ' "' + fragment_def['question_strings'][0].format(                        # TODO don't just use first
            entity=entity, property=property, question_date=question_date) + '"\n'
        for j in range(0, 2):
            intpn_i, relation = relations[j]
            intpn_str = INTERPRETATION_INDEX[intpn_i]
            lbl_i = j+1 if intpn_i == lbl_i else lbl_i
            prompt += f'  {j+1}. ' + fragment_def['interpretation_strings'][0][intpn_str].format(    # TODO don't just use first
                relation=relation, property=property, question_date=question_date, entity=entity) + '\n'
        prompt += '\n' + PROMPT_TEMPLATES[prompt_style][0]
        return lbl_i, lbl_str, prompt, entity, property

    def gen_prompts(df, class_):
        return [
            create_prompt(*row, class_)
            for row in zip(df['entityLabel'], df[f'propertyLabel{class_}'],
                           df['startTime1'], df['endTime1'], df['relationLabel1'],
                           df['startTime2'], df['endTime2'], df['relationLabel2'])
        ]
    prompts1 = gen_prompts(property_pairs_df, 1)
    prompts2 = gen_prompts(property_pairs_df, 2)
    prompts = [val for tup in zip(prompts1, prompts2) for val in tup]
    prompts_df = pd.DataFrame(prompts, columns=('label_nr', 'label_name', 'prompt', 'entity', 'property'))
    prompts_df['prompt_style'] = prompt_style
    prompts_df.to_json(
        os.path.join(output_dir, f"{fragment_def['key']}_prompts_{prompt_style}.jsonl"),
        orient='records', lines=True
    )


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Create a fragment of the commonsense reasoning benchmark given a '
                                                 'particular fragment definition file.')
    parser.add_argument('--fragment_def_path', type=str, required=True)
    parser.add_argument('--prompt_style', type=str, required=True, default='direct', choices=PROMPT_TEMPLATES.keys())
    parser.add_argument('--fragments_dir', type=str, default=FRAGMENTS_DIR)
    parser.add_argument('--query_results_dir', type=str, default=QUERY_RESULTS_DIR)
    parser.add_argument('--seed', type=int, default=42)  # TODO implement
    parser.add_argument('--reuse_query', action='store_true')
    _args = parser.parse_args()

    # Load the fragment definition file
    _fragment_key = _args.fragment_def_path.split('/')[-1].split('.')[0]
    _fragment_def = load_fragment_definition(_args.fragment_def_path)
    _fragment_def['key'] = _fragment_key

    # Query Wikidata
    _query_results_file = os.path.join(_args.query_results_dir, f"{_fragment_key}.csv")
    if not _args.reuse_query or not os.path.isfile(_query_results_file):
        query_wikidata(_fragment_def, _query_results_file)
    else:
        _mtime = os.stat(_query_results_file).st_mtime
        logger.info(f'Reusing query result {_query_results_file} from [{time.ctime(_mtime)}]')

    # Create the prompts
    create_fragment(_fragment_def, _query_results_file, _args.fragments_dir, prompt_style=_args.prompt_style)
