import argparse
import os
import re

import pandas as pd
from pandarallel import pandarallel
from dotenv import load_dotenv
from tqdm.auto import tqdm
from tenacity import (
    retry,
    stop_after_attempt,
    wait_random_exponential
)
import openai

from create_fragment import PROMPT_TEMPLATES

load_dotenv()


def _prepare():
    tqdm.pandas()
    pandarallel.initialize(progress_bar=True, nb_workers=4)


def prepare_for_local_api():
    _prepare()
    openai.api_key = 'anything'
    openai.api_base = os.getenv('LOCAL_API_URL')


def prepare_for_official_openai_api():
    _prepare()
    openai.api_key = os.getenv('OPENAI_API_KEY')


@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))
def _openai_chat_complete(prompt, model):
    response = openai.ChatCompletion.create(
        model=model,
        messages=[
                {"role": "system", "content": "You are a helpful assistant that reasons about the correct "
                                              "interpretation of ambiguous sentences."},
                {"role": "user", "content": prompt}
            ],
        max_tokens=512,
        headers={'ngrok-skip-browser-warning': ''}
    )
    return response


def query(prompts_df, model):
    prompts_df['completion'] = prompts_df['prompt'].parallel_apply(lambda prompt: _openai_chat_complete(prompt, model))
    return prompts_df


def _process_completion(row):
    completion = row['completion']
    completion_tokens = completion['usage']['completion_tokens']
    prompt_tokens = completion['usage']['prompt_tokens']
    finish_reason = completion['choices'][0]['finish_reason']
    message = completion['choices'][0]['message']['content']
    regex = PROMPT_TEMPLATES[row['prompt_style']][1]
    result = re.search(regex, message)
    if not result:
        return None, None, message, completion_tokens, prompt_tokens, finish_reason, False
    else:
        choice = result.group('choice')
        explanation = result.group('explanation')
        return choice, explanation, message, completion_tokens, prompt_tokens, finish_reason, True


def process_completions(prompts_df):
    new_columns = ['choice', 'explanation', 'full_completion', 'nr_tokens_compl', 'nr_tokens_prompt', 'finish_reason',
                   'success']
    prompts_df[new_columns] = prompts_df.apply(_process_completion, result_type='expand', axis=1)
    return prompts_df


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='')

    parser.add_argument('--fragment_file', type=str)
    parser.add_argument('--model', type=str)
    parser.add_argument('--api', type=str, choices=['openai_official', 'local'], default='local')
    parser.add_argument('--output_dir', type=str, default='outputs/')
    parser.add_argument('--sample_n', type=int, default=100)
    parser.add_argument('--sample_seed', type=int, default=0)
    parser.add_argument('--reuse_completions', action='store_true')
    parser.add_argument('--overwrite', action='store_true')

    _args = parser.parse_args()

    def _name(name='results'):
        return os.path.basename(_args.fragment_file).replace('prompts', name)

    _completion_path = os.path.join(_args.output_dir, _name('completions'))
    _results_path = os.path.join(_args.output_dir, _name('results'))

    if not _args.overwrite and os.path.exists(_results_path):
        print('Not overwriting existing results, exiting.')
        exit()

    if not (_args.reuse_completions and os.path.exists(_completion_path)):
        if _args.api == 'openai_official':
            prepare_for_official_openai_api()
        elif _args.api == 'local':
            prepare_for_local_api()
        else:
            raise ValueError('unsupported api')

        # read fragment and sample n instances
        _df = pd.read_json(_args.fragment_file, lines=True)
        _a = _df[_df['label_name'] == 'de_dicto'].sample(n=_args.sample_n//2, random_state=_args.sample_seed)
        _b = _df[_df['label_name'] == 'de_re'].sample(n=_args.sample_n//2, random_state=_args.sample_seed)
        _df = pd.concat((_a, _b))

        # query
        _df = query(_df, _args.model)
        _df.to_json(_completion_path, orient='records', lines=True)
    _df = pd.read_json(_completion_path, lines=True)

    # process completions
    _df = process_completions(_df)

    _df.to_json(_results_path, orient='records', lines=True)
